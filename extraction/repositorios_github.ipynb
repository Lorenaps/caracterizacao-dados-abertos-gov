{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração de dados do Github\n",
    "\n",
    "Pesquisando por iniciativas/projetos que utilizam Dados Abertos Governamentais através da [API do Github](https://developer.github.com/v3/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import logging\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_strings = [\n",
    "            'dados abertos',\n",
    "            'dados abertos brasil',\n",
    "            'dados abertos governo',\n",
    "            'dados abertos governamentais',\n",
    "            'dados governamentais',\n",
    "            'dados publicos abertos',\n",
    "            'dados do governo',\n",
    "            'analise de dados do governo',\n",
    "            'analise de dados governamentais',\n",
    "            'portal de dados do governo',\n",
    "            'portal de dados governamentais',\n",
    "            'portal publico do governo',\n",
    "            'portal de dados abertos do governo',\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a acesso a alguns recursos da API do github é preciso se autenticar, como aumentar o limite de requisições. Informações sobre autenticação podem ser encontradas [aqui](https://developer.github.com/v3/#authentication)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = ('<user_name>','<token>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rate': {'limit': 60, 'remaining': 57, 'reset': 1579879098},\n",
       " 'resources': {'core': {'limit': 60, 'remaining': 57, 'reset': 1579879098},\n",
       "  'graphql': {'limit': 0, 'remaining': 0, 'reset': 1579882078},\n",
       "  'integration_manifest': {'limit': 5000,\n",
       "   'remaining': 5000,\n",
       "   'reset': 1579882078},\n",
       "  'search': {'limit': 10, 'remaining': 10, 'reset': 1579878538},\n",
       "  'source_import': {'limit': 5, 'remaining': 5, 'reset': 1579878538}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = requests.get('https://api.github.com/rate_limit')\n",
    "t.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rate': {'limit': 5000, 'remaining': 5000, 'reset': 1579882080},\n",
       " 'resources': {'core': {'limit': 5000, 'remaining': 5000, 'reset': 1579882080},\n",
       "  'graphql': {'limit': 5000, 'remaining': 5000, 'reset': 1579882080},\n",
       "  'integration_manifest': {'limit': 5000,\n",
       "   'remaining': 5000,\n",
       "   'reset': 1579882080},\n",
       "  'search': {'limit': 30, 'remaining': 30, 'reset': 1579878540},\n",
       "  'source_import': {'limit': 100, 'remaining': 100, 'reset': 1579878540}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = requests.get('https://api.github.com/rate_limit', auth=credentials)\n",
    "t.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando limitação de extração de dados da API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'documentation_url': 'https://developer.github.com/v3/search/',\n",
       " 'message': 'Only the first 1000 search results are available'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_35 = 'https://api.github.com/search/repositories?q=stars%3A%3E1&sort=stars&order=desc&page=35'\n",
    "t = requests.get(page_35, auth=credentials)\n",
    "t.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Informações sobre a ferramenta de pesquisa da API podem ser encontradas [aqui](https://developer.github.com/v3/search/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base = 'https://api.github.com/search/repositories?q='"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos adicionar uma ordenação nos resultados, como quantidade de _stars_ de forma descrescente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort = '&sort=stars&order=desc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraindo informações gerais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=[\n",
    "        'id',\n",
    "        'full_name',\n",
    "        'description',\n",
    "        'owner_type', \n",
    "        'owner_api_url',\n",
    "        'owner_url',\n",
    "        'url',\n",
    "        'api_url',\n",
    "        'fork',\n",
    "        'created_at',\n",
    "        'updated_at',\n",
    "        'size',\n",
    "        'stargazers_count',\n",
    "        'language',\n",
    "        'has_issues',\n",
    "        'has_wiki',\n",
    "        'forks_count',\n",
    "        'forks',\n",
    "        'open_issues',\n",
    "        'watchers',\n",
    "        'timestamp_extract'\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_result(item):\n",
    "    \n",
    "    df = pd.DataFrame([[\n",
    "                        item.get('id'),\n",
    "                        item.get('full_name', None),\n",
    "                        item.get('description', None),      \n",
    "                        item.get('owner').get('type', None),\n",
    "                        item.get('owner').get('url', None),\n",
    "                        item.get('owner').get('html_url', None),\n",
    "                        item.get('html_url', None),\n",
    "                        item.get('url', None),\n",
    "                        item.get('fork', None),\n",
    "                        item.get('created_at', None),\n",
    "                        item.get('updated_at', None),\n",
    "                        item.get('size', None),\n",
    "                        item.get('stargazers_count', None),\n",
    "                        item.get('language', None),\n",
    "                        item.get('has_issues', None),\n",
    "                        item.get('has_wiki', None),\n",
    "                        item.get('forks_count', None),\n",
    "                        item.get('forks', None),\n",
    "                        item.get('open_issues', None),\n",
    "                        item.get('watchers', None),\n",
    "                        str(time.time()).split('.')[0]]], columns=columns)\n",
    "\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_results(data, results):\n",
    "    \n",
    "    for item in data.get('items', None):\n",
    "        \n",
    "        results = pd.concat([results, add_result(item)], ignore_index=True, sort=False)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "repositories_df = pd.DataFrame(columns=['id',\n",
    "                                    'full_name',\n",
    "                                    'description',\n",
    "                                    'owner_type', \n",
    "                                    'owner_api_url',\n",
    "                                    'owner_url',\n",
    "                                    'url',\n",
    "                                    'api_url',\n",
    "                                    'fork',\n",
    "                                    'created_at',\n",
    "                                    'updated_at',\n",
    "                                    'size',\n",
    "                                    'stargazers_count',\n",
    "                                    'language',\n",
    "                                    'has_issues',\n",
    "                                    'has_wiki',\n",
    "                                    'forks_count',\n",
    "                                    'forks',\n",
    "                                    'open_issues',\n",
    "                                    'watchers',\n",
    "                                    'timestamp_extract',\n",
    "                                    'commits',\n",
    "                                    'contributors',]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_pages(url, repositories_df):\n",
    "    \n",
    "    print('\\nPrimeira requisição')\n",
    "    \n",
    "    results = requests.get(url, auth=credentials)    \n",
    "    data = dict(results.json())\n",
    "    total = data.get('total_count', None)\n",
    "        \n",
    "    print(\">>> Foram encontrados {0} resultados. Extraindo...\".format(total))\n",
    "\n",
    "    repositories_df = extract_results(data, repositories_df)\n",
    "    \n",
    "    iterations = total // 30 \n",
    "    \n",
    "    for iteracao in range(0, iterations):        \n",
    "        header = dict(results.links)\n",
    "        \n",
    "        if header.get('next', False):\n",
    "            next_url = header.get('next').get('url')\n",
    "            \n",
    "            print(\"\\nNext url: {0}\".format(next_url))\n",
    "            \n",
    "            results = requests.get(next_url, auth=credentials)\n",
    "            data = dict(results.json())\n",
    "            repositories_df = extract_results(data, repositories_df)\n",
    "        \n",
    "    return repositories_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for string in search_strings:\n",
    "    url = url_base + string + sort\n",
    "    print(\"\\nExtraindo repositórios para a string: '{0}'\".format(string))\n",
    "    repositories_df = scroll_pages(url, repositories_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "repositories_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraindo Commits e Contributors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_commits(url_repo):\n",
    "    \n",
    "    commits_url = url_repo + '/commits'  \n",
    "    results = requests.get(commits_url, auth=credentials)\n",
    "    \n",
    "    # No caso do repositório estar vazio\n",
    "    if results.status_code == 409:\n",
    "        return None\n",
    "    \n",
    "    commits = len(results.json())\n",
    "\n",
    "    header = dict(results.links)\n",
    "    \n",
    "    while header.get('next', False):\n",
    "        next_url = header.get('next').get('url')        \n",
    "        results = requests.get(next_url, auth=credentials)\n",
    "        commits = commits + len(results.json())    \n",
    "        header = dict(results.links)\n",
    "\n",
    "\n",
    "    return commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_contributors(url_repo):\n",
    "    \n",
    "    contributors_url = url_repo + '/contributors'\n",
    "    results = requests.get(contributors_url, auth=credentials)\n",
    "    \n",
    "    # No caso do repositório estar vazio\n",
    "    if results.status_code == 204:\n",
    "        return None\n",
    "    \n",
    "    contributors = len(results.json())\n",
    "\n",
    "    header = dict(results.links)\n",
    "    \n",
    "    while header.get('next', False):\n",
    "        next_url = header.get('next').get('url')\n",
    "        results = requests.get(next_url, auth=credentials)\n",
    "        contributors = contributors + len(results.json())\n",
    "        header = dict(results.links)\n",
    "    \n",
    "    return contributors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "urls = repositories_df['api_url']\n",
    "\n",
    "for url in urls:\n",
    "        \n",
    "    print('\\n>>> ', url)\n",
    "    \n",
    "    repo = requests.get(url, auth=credentials)\n",
    "    repo = dict(repo.json())\n",
    "        \n",
    "    commits = extract_commits(url)\n",
    "    contributors = extract_contributors(url)\n",
    "\n",
    "    print(\"Tem {0} Commits - {1} Contributors\".format(commits,contributors))\n",
    "\n",
    "    repositories_df.loc[repositories_df[\"api_url\"] == url, 'commits'] = commits\n",
    "    repositories_df.loc[repositories_df[\"api_url\"] == url, 'contributors'] = contributors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repositories_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conferindo valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repositories_df.loc[repositories_df['commits'].isnull()][['api_url', 'commits', 'contributors']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repositories_df.loc[repositories_df['contributors'].isnull()][['api_url', 'commits', 'contributors']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/repositories_' + str(time.time()).split('.')[0] + '.csv'\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repositories_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraindo contribuidores dos repositórios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: Extrair locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_contributors = [ 'repo_id',\n",
    "                          'repo_name',\n",
    "                          'repo_url',\n",
    "                          'repo_api_url',\n",
    "                          'contributor_id',\n",
    "                          'contributor_login',\n",
    "                          'contributor_type',\n",
    "                          'contributor_url',\n",
    "                          'contributor_api_url',\n",
    "                          'timestamp_extract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_results(results):\n",
    "    \n",
    "    list_contributors = []\n",
    "\n",
    "    for result in results:\n",
    "        contributor = {}\n",
    "        \n",
    "        contributor = {\n",
    "            'contributor_id': result.get('id', None),\n",
    "            'contributor_login': result.get('login', None),\n",
    "            'contributor_type': result.get('type', None),\n",
    "            'contributor_url': result.get('html_url', None),\n",
    "            'contributor_api_url': result.get('url', None),\n",
    "        }\n",
    "\n",
    "        list_contributors.append(contributor)\n",
    "        \n",
    "    return list_contributors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contributors(url):\n",
    "\n",
    "    list_contributors = []\n",
    "    results = requests.get(url, auth=credentials)\n",
    "    \n",
    "    # No caso do repositório estar vazio\n",
    "    if results.status_code is 204:\n",
    "        return None\n",
    "    \n",
    "    contributors_results = results.json()\n",
    "    list_contributors = scroll_results(contributors_results)\n",
    "    \n",
    "    header = dict(results.links)\n",
    "    \n",
    "    while header.get('next', False):\n",
    "        next_url = header.get('next').get('url')\n",
    "        \n",
    "        print('\\t> Extraindo da próxima página: {0}'.format(next_url))\n",
    "            \n",
    "        results = requests.get(next_url, auth=credentials)\n",
    "        contributors_results = results.json()\n",
    "        list_contributors = list_contributors + scroll_results(contributors_results)    \n",
    "        header = dict(results.links)\n",
    "        \n",
    "    return list_contributors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_contributor(repo, contributor):\n",
    "            \n",
    "    df = pd.DataFrame([[\n",
    "                    repo.get('repo_id', None),\n",
    "                    repo.get('repo_name', None),\n",
    "                    repo.get('repo_url', None),      \n",
    "                    repo.get('repo_api_url', None),\n",
    "                    contributor.get('contributor_id', None),\n",
    "                    contributor.get('contributor_login', None),\n",
    "                    contributor.get('contributor_type', None),\n",
    "                    contributor.get('contributor_url', None),\n",
    "                    contributor.get('contributor_api_url', None),\n",
    "                    str(time.time()).split('.')[0]]], columns=columns_contributors)\n",
    "\n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_contributors(contributors_df, repo, contributors):\n",
    "    \n",
    "    for contributor in contributors:\n",
    "                \n",
    "        contributors_df = pd.concat([contributors_df, \n",
    "                                     add_contributor(repo, contributor)], \n",
    "                                    ignore_index=True, \n",
    "                                    sort=False)\n",
    "    return contributors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_contributors(repositories_df):\n",
    "    \n",
    "    contributors_df = pd.DataFrame(columns = columns_contributors)\n",
    "    urls = repositories_df['api_url']\n",
    "   \n",
    "    for url in urls:\n",
    "        print('\\nExtraindo contribuidores de: {0}'.format(url))\n",
    "\n",
    "        repo = {\n",
    "            'repo_id': repositories_df.loc[repositories_df[\"api_url\"] == url, 'id'].values[0],\n",
    "            'repo_name': repositories_df.loc[repositories_df[\"api_url\"] == url, 'full_name'].values[0],\n",
    "            'repo_url': repositories_df.loc[repositories_df[\"api_url\"] == url, 'url'].values[0],\n",
    "            'repo_api_url': url,\n",
    "        }\n",
    "        \n",
    "        url_contributors = url + '/contributors'        \n",
    "        contributors = get_contributors(url_contributors)\n",
    "        \n",
    "        if contributors:\n",
    "            contributors_df = save_contributors(contributors_df, repo, contributors)\n",
    "        \n",
    "    \n",
    "    return contributors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "result_contributors = search_contributors(repositories_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_contributors.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_contributors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/contributors_' + str(time.time()).split('.')[0] + '.csv'\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_contributors.to_csv(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
